{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z7/hhdyq2c544q40kc9g6q0kqd00000gn/T/ipykernel_83377/334480947.py:2: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
      "  from jax import lax, jit, grad, random, vmap, pmap, local_device_count, tree_map, jacfwd, jacrev\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import lax, jit, grad, random, vmap, pmap, local_device_count, tree_map, jacfwd, jacrev\n",
    "from jax.tree_util import tree_map, tree_reduce, tree_leaves\n",
    "from functools import partial\n",
    "from absl import logging\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import os\n",
    "import time\n",
    "import ml_collections\n",
    "import jax\n",
    "from jax.tree_util import tree_map\n",
    "from flax.training import train_state\n",
    "from flax import jax_utils\n",
    "from typing import Any, Callable, Sequence, Tuple, Optional, Dict\n",
    "from matplotlib import pyplot as plt\n",
    "from jaxpi.evaluator import BaseEvaluator\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"  # DETERMINISTIC\n",
    "from ml_collections import config_flags\n",
    "\n",
    "import optax\n",
    "\n",
    "from jaxpi import archs\n",
    "from jaxpi.utils import flatten_pytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 1.0\n",
    "t_0 = 0.0\n",
    "t_end = 50.0\n",
    "r = 1000.0\n",
    "n_samples = 50\n",
    "c = 0.01\n",
    "\n",
    "def solution(t):\n",
    "    return - t / (r*c) + jnp.log(u/r)\n",
    "\n",
    "def get_dataset():\n",
    "    t = jnp.linspace(t_0, t_end, n_samples)\n",
    "    u = solution(t)\n",
    "    return t,u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformSampler():\n",
    "    #@partial(pmap, static_broadcasted_argnums=(0,))\n",
    "    def data_generation():\n",
    "        dom = jnp.array([[0., 50.]])\n",
    "        dim = dom.shape[0]\n",
    "\n",
    "        batch = random.uniform(\n",
    "            random.PRNGKey(1234),\n",
    "            shape=(5, dim),\n",
    "            minval=dom[:, 0],\n",
    "            maxval=dom[:, 1],\n",
    "        )\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    weights: Dict\n",
    "    momentum: float\n",
    "\n",
    "    def apply_weights(self, weights, **kwargs):\n",
    "        \"\"\"Updates `weights` using running average  in return value.\n",
    "\n",
    "        Returns:\n",
    "          An updated instance of `self` with new weights updated by applying `running_average`,\n",
    "          and additional attributes replaced as specified by `kwargs`.\n",
    "        \"\"\"\n",
    "\n",
    "        running_average = (\n",
    "            lambda old_w, new_w: old_w * self.momentum + (1 - self.momentum) * new_w\n",
    "        )\n",
    "        weights = tree_map(running_average, self.weights, weights)\n",
    "        weights = lax.stop_gradient(weights)\n",
    "\n",
    "        return self.replace(\n",
    "            step=self.step,\n",
    "            params=self.params,\n",
    "            opt_state=self.opt_state,\n",
    "            weights=weights,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "def _create_arch(config):\n",
    "    if config.arch_name == \"Mlp\":\n",
    "        arch = archs.Mlp(**config)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Arch {config.arch_name} not supported yet!\")\n",
    "\n",
    "    return arch\n",
    "\n",
    "\n",
    "def _create_optimizer(config):\n",
    "    if config.optimizer == \"Adam\":\n",
    "        lr = optax.exponential_decay(\n",
    "            init_value=config.learning_rate,\n",
    "            transition_steps=config.decay_steps,\n",
    "            decay_rate=config.decay_rate,\n",
    "        )\n",
    "        tx = optax.adam(\n",
    "            learning_rate=lr, b1=config.beta1, b2=config.beta2, eps=config.eps\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Optimizer {config.optimizer} not supported yet!\")\n",
    "\n",
    "    # Gradient accumulation\n",
    "    if config.grad_accum_steps > 1:\n",
    "        tx = optax.MultiSteps(tx, every_k_schedule=config.grad_accum_steps)\n",
    "\n",
    "    return tx\n",
    "\n",
    "\n",
    "# Create nn module from config file\n",
    "def _create_train_state(config):\n",
    "    # Initialize network\n",
    "    arch = _create_arch(config.arch) # nn.module\n",
    "    x = jnp.ones(config.input_dim)\n",
    "    params = arch.init(random.PRNGKey(config.seed), x)\n",
    "\n",
    "    # Initialize optax optimizer\n",
    "    tx = _create_optimizer(config.optim)\n",
    "\n",
    "    # Convert config dict to dict\n",
    "    init_weights = dict(config.weighting.init_weights)\n",
    "\n",
    "    state = TrainState.create(\n",
    "        apply_fn=arch.apply,\n",
    "        params=params,\n",
    "        tx=tx,\n",
    "        weights=init_weights,\n",
    "        momentum=config.weighting.momentum,\n",
    "    )\n",
    "\n",
    "    return jax_utils.replicate(state)\n",
    "\n",
    "\n",
    "class PINN:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.state = _create_train_state(config)\n",
    "\n",
    "    def u_net(self, params, *args):\n",
    "        raise NotImplementedError(\"Subclasses should implement this!\")\n",
    "\n",
    "    def r_net(self, params, *args):\n",
    "        raise NotImplementedError(\"Subclasses should implement this!\")\n",
    "\n",
    "    def losses(self, params, batch, *args):\n",
    "        raise NotImplementedError(\"Subclasses should implement this!\")\n",
    "\n",
    "    def compute_diag_ntk(self, params, batch, *args):\n",
    "        raise NotImplementedError(\"Subclasses should implement this!\")\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def loss(self, params, weights, batch, *args):\n",
    "        # Compute losses\n",
    "        losses = self.losses(params, batch, *args)\n",
    "        # Compute weighted loss\n",
    "        weighted_losses = tree_map(lambda x, y: x * y, losses, weights)\n",
    "        # Sum weighted losses\n",
    "        loss = tree_reduce(lambda x, y: x + y, weighted_losses)\n",
    "        return loss\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def compute_weights(self, params, batch, *args):\n",
    "        if self.config.weighting.scheme == \"grad_norm\":\n",
    "            # Compute the gradient of each loss w.r.t. the parameters\n",
    "            grads = jacrev(self.losses)(params, batch, *args)\n",
    "\n",
    "            # Compute the grad norm of each loss\n",
    "            grad_norm_dict = {}\n",
    "            for key, value in grads.items():\n",
    "                flattened_grad = flatten_pytree(value)\n",
    "                grad_norm_dict[key] = jnp.linalg.norm(flattened_grad)\n",
    "\n",
    "            # Compute the mean of grad norms over all losses\n",
    "            mean_grad_norm = jnp.mean(jnp.stack(tree_leaves(grad_norm_dict)))\n",
    "            # Grad Norm Weighting\n",
    "            w = tree_map(lambda x: (mean_grad_norm / x), grad_norm_dict)\n",
    "\n",
    "        return w\n",
    "\n",
    "    @partial(pmap, axis_name=\"batch\", static_broadcasted_argnums=(0,))\n",
    "    def update_weights(self, state, batch, *args):\n",
    "        weights = self.compute_weights(state.params, batch, *args)\n",
    "        weights = lax.pmean(weights, \"batch\")\n",
    "        state = state.apply_weights(weights=weights)\n",
    "        return state\n",
    "\n",
    "    @partial(pmap, axis_name=\"batch\", static_broadcasted_argnums=(0,))\n",
    "    def step(self, state, batch, *args):\n",
    "        grads = grad(self.loss)(state.params, state.weights, batch, *args)\n",
    "        grads = lax.pmean(grads, \"batch\")\n",
    "        state = state.apply_gradients(grads=grads)\n",
    "        return state\n",
    "\n",
    "\n",
    "class ForwardIVP(PINN):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        if config.weighting.use_causal:\n",
    "            self.tol = config.weighting.causal_tol\n",
    "            self.num_chunks = config.weighting.num_chunks\n",
    "            self.M = jnp.triu(jnp.ones((self.num_chunks, self.num_chunks)), k=1).T\n",
    "\n",
    "\n",
    "class ForwardBVP(PINN):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks ok until here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaseZero(ForwardIVP):\n",
    "    def __init__(self, config, t_star, u0):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.u0 = u0\n",
    "        self.t_star = t_star\n",
    "\n",
    "        self.t0 = t_star[0]\n",
    "        self.t1 = t_star[-1]\n",
    "\n",
    "        # Predictions over t\n",
    "        self.u_pred_fn = vmap(self.u_net, (0, None)) # -------------- DEBUG\n",
    "        self.r_pred_fn = vmap(self.r_net, (0, None)) # -------------- DEBUG\n",
    "\n",
    "\n",
    "    # Prediction from net for initial value\n",
    "    def u_net(self, params, t):\n",
    "        u = self.state.apply_fn(params, t) # -------------- DEBUG\n",
    "        return u[0]\n",
    "\n",
    "    # Gradient of the neural net\n",
    "    def grad_net(self, params, t):\n",
    "        u_t = grad(self.u_net, argnums=1)(params, t)\n",
    "        return u_t\n",
    "\n",
    "    # Residual of the neural net\n",
    "    def r_net(self, params, t):\n",
    "        u_t = self.grad_net(params, t)\n",
    "        return u_t + 0.1\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def res_and_w(self, params, batch):\n",
    "        \"Compute residuals and weights for causal training\"\n",
    "        # Sort time coordinates\n",
    "        t_sorted = batch[:, 0].sort()\n",
    "        r_pred = vmap(self.r_net, (None, 0))(params, t_sorted) # -------------- DEBUG\n",
    "        # Split residuals into chunks\n",
    "        r_pred = r_pred.reshape(self.num_chunks, -1)\n",
    "        l = jnp.mean(r_pred**2, axis=1)\n",
    "        w = lax.stop_gradient(jnp.exp(-self.tol * (self.M @ l)))\n",
    "        return l, w\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def losses(self, params, batch):\n",
    "        # Initial condition loss\n",
    "        u_pred = self.u_net(params, self.t0) # -------------- DEBUG\n",
    "        ics_loss = jnp.mean((self.u0 - u_pred) ** 2)\n",
    "\n",
    "        # Residual loss\n",
    "        if self.config.weighting.use_causal == True:\n",
    "            l, w = self.res_and_w(params, batch)\n",
    "            res_loss = jnp.mean(l * w)\n",
    "        else:\n",
    "            r_pred = vmap(self.r_net, (None, 0))(params, batch[:, 0]) # -------------- DEBUG\n",
    "            res_loss = jnp.mean((r_pred) ** 2)\n",
    "\n",
    "        loss_dict = {\"ics\": ics_loss, \"res\": res_loss}\n",
    "        return loss_dict\n",
    "\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def compute_l2_error(self, params, u_test):\n",
    "        u_pred = self.u_pred_fn(params, self.t_star)\n",
    "        error = jnp.linalg.norm(u_pred - u_test) / jnp.linalg.norm(u_test)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(config: ml_collections.ConfigDict, workdir: str):\n",
    "\n",
    "    # Get dataset\n",
    "    t_star, u_ref  = get_dataset()\n",
    "    u0 = u_ref[0]\n",
    "\n",
    "    t0 = t_star[0]\n",
    "    t_end = t_star[-1]\n",
    "\n",
    "    # Define domain\n",
    "    dom = jnp.array([[t0, t_end]])\n",
    "\n",
    "    # Define residual sampler\n",
    "    res_sampler = iter(UniformSampler(dom, config.training.batch_size_per_device))\n",
    "\n",
    "    # Initialize model\n",
    "    model = CaseZero(config, t_star, u0)\n",
    "\n",
    "    print(\"Waiting for JIT...\")\n",
    "    start_time = time.time()\n",
    "    for step in range(config.training.max_steps):\n",
    "        batch = next(res_sampler)\n",
    "        model.state = model.step(model.state, batch)\n",
    "\n",
    "        if config.weighting.scheme in [\"grad_norm\", \"ntk\"]:\n",
    "            if step % config.weighting.update_every_steps == 0:\n",
    "                model.state = model.update_weights(model.state, batch)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FATAL Flags parsing error: Unknown command line flag 'f'\n",
      "Pass --helpshort or --helpfull to see help on flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/absl/app.py:156\u001b[0m, in \u001b[0;36mparse_flags_with_usage\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m FLAGS(args)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/absl/flags/_flagvalues.py:685\u001b[0m, in \u001b[0;36mFlagValues.__call__\u001b[0;34m(self, argv, known_only)\u001b[0m\n\u001b[1;32m    684\u001b[0m   suggestions \u001b[38;5;241m=\u001b[39m _helpers\u001b[38;5;241m.\u001b[39mget_flag_suggestions(name, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m--> 685\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _exceptions\u001b[38;5;241m.\u001b[39mUnrecognizedFlagError(\n\u001b[1;32m    686\u001b[0m       name, value, suggestions\u001b[38;5;241m=\u001b[39msuggestions)\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmark_as_parsed()\n",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m: Unknown command line flag 'f'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 25\u001b[0m     app\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/absl/app.py:300\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m   args \u001b[38;5;241m=\u001b[39m _run_init(\n\u001b[1;32m    301\u001b[0m       sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;28;01mif\u001b[39;00m argv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m argv,\n\u001b[1;32m    302\u001b[0m       flags_parser,\n\u001b[1;32m    303\u001b[0m   )\n\u001b[1;32m    304\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m _init_callbacks:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/absl/app.py:369\u001b[0m, in \u001b[0;36m_run_init\u001b[0;34m(argv, flags_parser)\u001b[0m\n\u001b[1;32m    368\u001b[0m logging\u001b[38;5;241m.\u001b[39muse_absl_handler()\n\u001b[0;32m--> 369\u001b[0m args \u001b[38;5;241m=\u001b[39m _register_and_parse_flags_with_usage(\n\u001b[1;32m    370\u001b[0m     argv\u001b[38;5;241m=\u001b[39margv,\n\u001b[1;32m    371\u001b[0m     flags_parser\u001b[38;5;241m=\u001b[39mflags_parser,\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m faulthandler:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/absl/app.py:216\u001b[0m, in \u001b[0;36m_register_and_parse_flags_with_usage\u001b[0;34m(argv, flags_parser)\u001b[0m\n\u001b[1;32m    215\u001b[0m original_argv \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;28;01mif\u001b[39;00m argv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m argv\n\u001b[0;32m--> 216\u001b[0m args_to_main \u001b[38;5;241m=\u001b[39m flags_parser(original_argv)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m FLAGS\u001b[38;5;241m.\u001b[39mis_parsed():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/absl/app.py:166\u001b[0m, in \u001b[0;36mparse_flags_with_usage\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    165\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPass --helpshort or --helpfull to see help on flags.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 166\u001b[0m sys\u001b[38;5;241m.\u001b[39mexit(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2121\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2119\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2120\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2121\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mInteractiveTB\u001b[38;5;241m.\u001b[39mget_exception_only(etype,\n\u001b[1;32m   2122\u001b[0m                                                      value))\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mstructured_traceback(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructured_traceback(\n\u001b[1;32m    569\u001b[0m             etype,\n\u001b[1;32m    570\u001b[0m             evalue,\n\u001b[1;32m    571\u001b[0m             (etb, chained_exc_ids),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    572\u001b[0m             chained_exceptions_tb_offset,\n\u001b[1;32m    573\u001b[0m             context,\n\u001b[1;32m    574\u001b[0m         )\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FormattedTB\u001b[38;5;241m.\u001b[39mstructured_traceback(\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;28mself\u001b[39m, etype, evalue, etb, tb_offset, number_of_lines_of_context\n\u001b[1;32m   1437\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m VerboseTB\u001b[38;5;241m.\u001b[39mstructured_traceback(\n\u001b[1;32m   1327\u001b[0m         \u001b[38;5;28mself\u001b[39m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[1;32m   1328\u001b[0m     )\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1171\u001b[0m ):\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m   1174\u001b[0m                                                            tb_offset)\n\u001b[1;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1064\u001b[0m )\n\u001b[1;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(cf\u001b[38;5;241m.\u001b[39mtb_frame)\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "\n",
    "jax.config.update(\"jax_default_matmul_precision\", \"highest\")\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string(\"workdir\", \".\", \"Directory to store model data.\")\n",
    "\n",
    "config_flags.DEFINE_config_file(\n",
    "    \"config\",\n",
    "    \"./configs/default.py\",\n",
    "    \"File path to the training hyperparameter configuration.\",\n",
    "    lock_config=True,\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate(FLAGS.config, FLAGS.workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
